{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b74c7578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "95\n",
      "[[0.94285714 1.         0.98591549 ... 0.78688525 0.71875    0.84      ]\n",
      " [0.55714286 0.77272727 0.78873239 ... 0.63934426 0.65625    0.66      ]\n",
      " [0.64285714 0.75757576 0.70422535 ... 0.6557377  0.59375    0.66      ]\n",
      " ...\n",
      " [0.37142857 0.34848485 0.28169014 ... 0.8852459  0.765625   0.76      ]\n",
      " [0.37142857 0.43939394 0.47887324 ... 0.85245902 0.765625   0.68      ]\n",
      " [0.37142857 0.46969697 0.42253521 ... 0.78688525 0.625      0.6       ]] [[0.73626374 0.73255814 0.46511628 ... 0.44206009 0.32291667 0.25806452]\n",
      " [0.74725275 0.70930233 0.34883721 ... 0.         0.         0.27956989]\n",
      " [0.72527473 0.79069767 0.44186047 ... 0.22317597 0.13541667 0.        ]\n",
      " ...\n",
      " [0.86813187 0.88372093 0.58139535 ... 0.58369099 0.36458333 0.29749104]\n",
      " [0.9010989  0.8372093  0.39534884 ... 0.82403433 0.29166667 0.15770609]\n",
      " [0.89010989 0.87209302 0.51162791 ... 0.57939914 0.49479167 0.37634409]] [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "Epoch 1/32\n",
      "3/3 [==============================] - 2s 92ms/step - loss: 1.9391 - accuracy: 0.7789\n",
      "Epoch 2/32\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 3/32\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/32\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/32\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/32\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/32\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/32\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/32\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/32\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/32\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/32\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 13/32\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 14/32\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 15/32\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16/32\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 17/32\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 18/32\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 19/32\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/32\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 21/32\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 22/32\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 23/32\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 24/32\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 25/32\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 26/32\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 27/32\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 28/32\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 29/32\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 30/32\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 31/32\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 32/32\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 20ms/step\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n",
      "Prediction: 0, True Label: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 45.9720 - accuracy: 0.0000e+00\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "# Get the list of files in the folder\n",
    "testing_files = os.listdir('../datasets/New/Thumb')\n",
    "training_files = os.listdir('../datasets/New/HandClose')\n",
    "\n",
    "testing_data = []\n",
    "training_data = []\n",
    "\n",
    "obj = {\n",
    "    \"HandClose\": 0,\n",
    "    \"Thumb\": 1,\n",
    "    \"Index\": 2,\n",
    "    \"Middle\": 3,\n",
    "    \"Ring\": 4,\n",
    "    \"Pinky\": 5\n",
    "}\n",
    "\n",
    "#Testing Data\n",
    "for file in testing_files:\n",
    "    d = {}\n",
    "    with open(f'../datasets/New/Thumb/{file}', 'r') as f:\n",
    "        l = [int(line.strip()) for line in f.readlines()]\n",
    "        d['data'] = l\n",
    "        d['label'] = \"Thumb\"\n",
    "        testing_data.append(d)\n",
    "print(len(testing_data))\n",
    "\n",
    "#Training Data\n",
    "for file in training_files:\n",
    "    d = {}\n",
    "    with open(f'../datasets/New/HandClose/{file}', 'r') as f:\n",
    "        l = [int(line.strip()) for line in f.readlines()]\n",
    "        d['data'] = l\n",
    "        d['label'] = \"HandClose\"\n",
    "        training_data.append(d)\n",
    "print(len(training_data))\n",
    "\n",
    "\n",
    "x_test_data = [[int(x) for x in data['data']] for data in testing_data]\n",
    "y_test_data_c = [obj[data['label']] for data in testing_data]\n",
    "\n",
    "x_train_data = [[int(x) for x in data['data']] for data in training_data]\n",
    "y_train_data_c = [obj[data['label']] for data in training_data]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_test_data_norm = scaler.fit_transform(x_test_data)\n",
    "x_train_data_norm = scaler.fit_transform(x_train_data)\n",
    "\n",
    "x_test_data = np.array(x_test_data_norm)\n",
    "x_train_data = np.array(x_train_data_norm)\n",
    "\n",
    "y_test_data = np.array(y_test_data_c)\n",
    "y_train_data = np.array(y_train_data_c)\n",
    "\n",
    "y_test_data = tf.keras.utils.to_categorical(y_test_data, num_classes)\n",
    "y_train_data = tf.keras.utils.to_categorical(y_train_data, num_classes)\n",
    "\n",
    "print(x_test_data, x_train_data, y_test_data, y_train_data)\n",
    "\n",
    "dim = 499\n",
    "drpt = 0.1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(dim, activation='relu', input_shape=(499,)),\n",
    "    tf.keras.layers.Dropout(drpt),\n",
    "    tf.keras.layers.Dense(dim, activation='relu'),\n",
    "    tf.keras.layers.Dropout(drpt),\n",
    "    tf.keras.layers.Dense(dim, activation='relu'),\n",
    "    tf.keras.layers.Dropout(drpt),\n",
    "    tf.keras.layers.Dense(dim, activation='relu'),\n",
    "    tf.keras.layers.Dropout(drpt),\n",
    "    tf.keras.layers.Dense(dim, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(drpt),\n",
    "    tf.keras.layers.Dense(dim, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(drpt),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile the model with a categorical cross-entropy loss function\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train_data, y_train_data, epochs=32, batch_size=32)\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test_data)\n",
    "for i in range(len(predictions)):\n",
    "    pred_label = np.argmax(predictions[i])\n",
    "    true_label = y_test_data_c[i]\n",
    "    print(f\"Prediction: {pred_label}, True Label: {true_label}\")\n",
    "    \n",
    "accuracy = model.evaluate(x_test_data, y_test_data)[1]\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebda58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
